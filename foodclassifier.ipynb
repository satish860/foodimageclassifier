{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a687e0-d93d-4b27-b015-d0e318ade727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets,models\n",
    "import torchvision.transforms as tt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader,random_split,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from fastprogress.fastprogress import master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "008f13e3-456f-41a8-b66f-feb74ae0889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "train_tfms = tt.Compose([tt.Resize(256),\n",
    "                         tt.CenterCrop(224),\n",
    "                         tt.ToTensor(), \n",
    "                         tt.Normalize(*stats,inplace=True)])\n",
    "valid_tfms = tt.Compose([tt.Resize([224,224]),tt.ToTensor(), tt.Normalize(*stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac68469-dc3a-4ded-8681-e9d46ea6e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.ImageFolder('food-101-subset/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba720b38-aa8e-4a20-9ad2-c13c164087ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,ds,transformer):\n",
    "        self.ds = ds\n",
    "        self.transform = transformer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image,label = self.ds[idx]\n",
    "        img = self.transform(image)\n",
    "        return img,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df5eab07-6524-42df-876d-874c3500dcc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16160, 4040)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len=0.8*len(ds)\n",
    "val_len = len(ds) - train_len\n",
    "int(train_len),int(val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f009f201-f128-4f61-8c8c-826ef373ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,val_ds = random_split(dataset=ds,lengths=[int(train_len),int(val_len)],generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff36b19-7e8c-4c82-be07-5267a49ebce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds = CustomDataset(train_ds.dataset,train_tfms)\n",
    "v_ds = CustomDataset(val_ds.dataset,valid_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e59e0a3-2bee-4131-80bf-a1a4f4f13d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dl = DataLoader(t_ds, batch_size, shuffle=True, pin_memory=True)\n",
    "valid_dl = DataLoader(v_ds, batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c5f19dd-300d-4815-9350-c37b1d318880",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self,x):\n",
    "        return torch.flatten(x,1)\n",
    "\n",
    "class FoodImageClassifer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.body = mobilenet.features\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1280,101))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.body(x)\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1) \n",
    "        return self.head(x)\n",
    "    \n",
    "    def freeze(self):\n",
    "        for name,param in self.body.named_parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfd046ba-e259-4da9-a537-2dc6a6b43517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs,model,train_dl,valid_dl,loss_fn,opt):\n",
    "    mb = master_bar(range(epochs))\n",
    "    mb.write(['epoch','train_loss','valid_loss','trn_acc','val_acc'],table=True)\n",
    "\n",
    "    for i in mb:    \n",
    "        trn_loss,val_loss = 0.0,0.0\n",
    "        trn_acc,val_acc = 0,0\n",
    "        trn_n,val_n = len(train_dl.dataset),len(valid_dl.dataset)\n",
    "        model.train()\n",
    "        for xb,yb in progress_bar(train_dl,parent=mb):\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            opt.zero_grad()\n",
    "            loss = loss_fn(out,yb)\n",
    "            _,pred = torch.max(out.data, 1)\n",
    "            trn_acc += (pred == yb).sum().item()\n",
    "            trn_loss += loss.item()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        trn_loss /= mb.child.total\n",
    "        trn_acc /= trn_n\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for xb,yb in progress_bar(valid_dl,parent=mb):\n",
    "                xb,yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = loss_fn(out,yb)\n",
    "                val_loss += loss.item()\n",
    "                _,pred = torch.max(out.data, 1)\n",
    "                val_acc += (pred == yb).sum().item()\n",
    "        val_loss /= mb.child.total\n",
    "        val_acc /= val_n\n",
    "\n",
    "        mb.write([i,f'{trn_loss:.6f}',f'{val_loss:.6f}',f'{trn_acc:.6f}',f'{val_acc:.6f}'],table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92308d3e-9858-4c59-ad78-412a2c7cd528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>trn_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.816711</td>\n",
       "      <td>1.739123</td>\n",
       "      <td>0.374653</td>\n",
       "      <td>0.598564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = FoodImageClassifer()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft =  optim.Adam(model.parameters(), lr=1e-4)\n",
    "#model.freeze()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "fit(1,model=model,train_dl=train_dl,valid_dl=valid_dl,loss_fn=criterion,opt=optimizer_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff7e3863-941b-4270-8f6c-b11ca52133cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>trn_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.551284</td>\n",
       "      <td>1.188755</td>\n",
       "      <td>0.626931</td>\n",
       "      <td>0.705891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.090450</td>\n",
       "      <td>0.957794</td>\n",
       "      <td>0.731832</td>\n",
       "      <td>0.758317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.773461</td>\n",
       "      <td>0.748548</td>\n",
       "      <td>0.806980</td>\n",
       "      <td>0.805099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.533341</td>\n",
       "      <td>0.640974</td>\n",
       "      <td>0.871089</td>\n",
       "      <td>0.824455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.357086</td>\n",
       "      <td>0.563184</td>\n",
       "      <td>0.919455</td>\n",
       "      <td>0.842871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit(5,model=model,train_dl=train_dl,valid_dl=valid_dl,loss_fn=criterion,opt=optimizer_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9340965e-fb60-4360-adf3-749bf99f8fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'food_classifier.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33439d95-db4a-4289-a6b0-9941fc2265b3",
   "metadata": {},
   "source": [
    "# Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "428446e8-aa54-4ccb-83da-42367e5c3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FoodImageClassifer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d86be557-1d17-4dd9-9dc8-0394cfaf51d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('food_classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fad7812e-c704-4364-bade-1985cf090cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e198ef0-24c8-4363-badd-2e62d0965710",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = datasets.ImageFolder('food-101/images/',valid_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61ec741e-04ee-431b-b23e-ecbe7a0a7963",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_dl = DataLoader(test_ds, batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8889a35c-044b-4d3e-b462-a6941031703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fit(epochs,model,test_dl,loss_fn):\n",
    "    mb = master_bar(range(epochs))\n",
    "    mb.write(['epoch','test_loss','test_acc'],table=True)\n",
    "\n",
    "    for i in mb:    \n",
    "        test_loss = 0.0\n",
    "        test_acc = 0\n",
    "        test_n = len(test_dl.dataset)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for xb,yb in progress_bar(test_dl,parent=mb):\n",
    "                xb,yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = loss_fn(out,yb)\n",
    "                test_loss += loss.item()\n",
    "                _,pred = torch.max(out.data, 1)\n",
    "                test_acc += (pred == yb).sum().item()\n",
    "        test_loss /= mb.child.total\n",
    "        test_acc /= test_n\n",
    "\n",
    "        mb.write([i,f'{test_loss:.6f}',f'{test_acc:.6f}'],table=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "096a2832-fd3f-4289-a930-cf8c1065a1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.232726</td>\n",
       "      <td>0.685723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_fit(1,model,test_dl,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353dfd4f-09a1-4df3-9347-b4ffb241f4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
