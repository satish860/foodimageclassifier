{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "701cc90b-8564-41db-bd8e-4b3efe718e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c164f9f1-abd5-40a2-8583-5d4408a1a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torchvision import datasets,models\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import Dataset,random_split,DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f05acca8-acfb-4ad7-8f8c-50dd2e346f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "train_tfms = tt.Compose([tt.Resize(256),\n",
    "                         tt.CenterCrop(224),\n",
    "                         tt.ToTensor(), \n",
    "                         tt.Normalize(*stats,inplace=True)])\n",
    "valid_tfms = tt.Compose([tt.Resize([224,224]),tt.ToTensor(), tt.Normalize(*stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddf7e742-f982-4e73-a9c8-5c473f732bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.ImageFolder('food-101-subset/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ae2a997-b082-4f2b-85cf-1def93116e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,ds,transformer):\n",
    "        self.ds = ds\n",
    "        self.transform = transformer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image,label = self.ds[idx]\n",
    "        img = self.transform(image)\n",
    "        return img,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bbcf108-7775-4509-8cff-127e37341c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16160, 4040)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len=0.8*len(ds)\n",
    "val_len = len(ds) - train_len\n",
    "int(train_len),int(val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0f21b42-e68a-4b16-b55a-2e6c42976b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,val_ds = random_split(dataset=ds,lengths=[int(train_len),int(val_len)],generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93fb9577-f452-4001-b66b-10749bd5ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds = CustomDataset(train_ds.dataset,train_tfms)\n",
    "v_ds = CustomDataset(val_ds.dataset,valid_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9a0db3d-cd38-405e-92a7-0ace889a4293",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dl = DataLoader(t_ds, batch_size, shuffle=True, pin_memory=True)\n",
    "valid_dl = DataLoader(v_ds, batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0034a55b-4a6d-466c-9d05-90cf9c722b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self,x):\n",
    "        return torch.flatten(x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f19daacd-98b0-49d8-83ac-25e919937a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodImageClassifer(pl.LightningModule):\n",
    "    def __init__(self,learning_rate,batch_size=32):\n",
    "        super().__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.body = mobilenet.features\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1280,101))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.body(x)\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1) \n",
    "        return self.head(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return loss\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "         return DataLoader(t_ds, self.batch_size, shuffle=True, pin_memory=True,num_workers=7)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(v_ds, self.batch_size, pin_memory=True,num_workers=7)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        val_loss = F.cross_entropy(y_hat, y)\n",
    "        return val_loss\n",
    "    \n",
    "    def freeze(self):\n",
    "        for name,param in self.body.named_parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3db4e36d-edfc-4c1e-9bfb-451c9ae8e5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using 1 batch(es).\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Skipping learning rate finder since fast_dev_run is enabled.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr_find': None}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FoodImageClassifer(1e-3)\n",
    "trainer = pl.Trainer(gpus=1,auto_lr_find=True)\n",
    "trainer.tune(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0eae573b-41ef-4467-8169-14d0923525e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | body | Sequential | 2.2 M \n",
      "1 | head | Sequential | 129 K \n",
      "------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.413     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327d94add7814adaabed3da54ae3b652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d07dcfd-e566-4a98-8bb9-2a8e5dceb094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FoodImageClassifer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d58075-2504-4100-8a40-085271ed85ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
